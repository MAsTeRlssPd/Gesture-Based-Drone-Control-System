âœ‹ Gesture-Based Drone Control System (AI + Computer Vision)

A real-time AI-powered hand gesture recognition system that controls drone-like commands using a webcam. The project uses hand landmarks, machine learning, and live gesture classification to simulate intelligent drone control â€” including takeoff, landing, movement, speed control, and photo capture.

This system is built using computer vision + ML pipeline:

Dataset collection

Model training

Real-time gesture inference & command engine

ğŸš€ Features

ğŸ“· Real-time hand tracking using MediaPipe

ğŸ§  ML-based gesture classification (XGBoost)

ğŸ® Gesture â†’ Command mapping

ğŸ”’ Safety lock system (Takeoff required before commands)

âš¡ Dynamic speed control using finger distance

ğŸ“¸ Gesture-triggered photo capture

ğŸ“Š Confidence filtering to avoid false commands

ğŸ§¾ Custom dataset generation pipeline

ğŸ›  Tech Stack

Python

OpenCV

MediaPipe Tasks API

NumPy

Pandas

Scikit-learn

XGBoost

Pickle (model persistence)

ğŸ“Œ Supported Gestures / Commands
Gesture Label	Command
UP	Move Up
DOWN	Move Down
LEFT	Move Left
RIGHT	Move Right
FORWARD	Move Forward
BACKWARD	Move Backward
BACKFLIP	Flip
HOVER	Hover
TAKEOFF	Unlock / Start
LAND	Stop / Lock
TAKE A PICTURE	Save frame
SPEED	Enter speed mode

ğŸ“Š Model Details

Algorithm: XGBoost Classifier

Input Features: 63 landmark coordinates

Confidence Threshold: 95%

Low confidence â†’ defaults to HOVER

Reduces false triggers

ğŸ¯ Key Innovations

End-to-end ML pipeline (data â†’ training â†’ inference)

Gesture confidence filtering

Dynamic speed control via geometry

Lock/unlock safety mechanism

Gesture-triggered camera system

Real-time visual feedback UI

Modular design for real drone integration

ğŸ Use Cases

Gesture-based robotics control

Drone command systems

Touchless interfaces

Accessibility control systems

AI + CV hackathon demos

Smart surveillance control
